{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> SHREYAANS NAHATA: 19BCE2686 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q01: Implement Decision tree classifier for breast cancer Wisconsin dataset (load_breast_cancer) and evaluate the algorithm with precision, recall sensitivity and specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:  ['malignant' 'benign']\n",
      "Feature Names:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "print('Target Names: ', data.target_names)\n",
    "print('Feature Names: ', data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the data attributes and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the data: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "X = data.data      # Data attributes\n",
    "y = data.target    # Target Labels\n",
    "print('Number of examples in the data:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First four rows in the variable 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      "  1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      "  6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      "  1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      "  4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02 8.690e-02\n",
      "  7.017e-02 1.812e-01 5.667e-02 5.435e-01 7.339e-01 3.398e+00 7.408e+01\n",
      "  5.225e-03 1.308e-02 1.860e-02 1.340e-02 1.389e-02 3.532e-03 2.499e+01\n",
      "  2.341e+01 1.588e+02 1.956e+03 1.238e-01 1.866e-01 2.416e-01 1.860e-01\n",
      "  2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
      "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
      "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
      "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
      "  3.613e-01 8.758e-02]\n",
      " [1.142e+01 2.038e+01 7.758e+01 3.861e+02 1.425e-01 2.839e-01 2.414e-01\n",
      "  1.052e-01 2.597e-01 9.744e-02 4.956e-01 1.156e+00 3.445e+00 2.723e+01\n",
      "  9.110e-03 7.458e-02 5.661e-02 1.867e-02 5.963e-02 9.208e-03 1.491e+01\n",
      "  2.650e+01 9.887e+01 5.677e+02 2.098e-01 8.663e-01 6.869e-01 2.575e-01\n",
      "  6.638e-01 1.730e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 10, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Decision Tree Classifier on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting labels on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Accuracy Score, Precision Score, Recall Sensitivity and Specificity on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[173   0]\n",
      " [  0 282]]\n",
      "Accuracy Score on train data: 100.0\n",
      "Precision Score on train data: 100.0\n",
      "Recall Sensitivity of train data: 100.0\n",
      "Specificity of train data: 100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "confusion = confusion_matrix(y_true=y_train, y_pred=clf.predict(X_train))\n",
    "print('Confusion Matrix: \\n', confusion)\n",
    "\n",
    "# Calculating the sensitivity\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "\n",
    "# Calculating the specificity\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "print('Accuracy Score on train data:', accuracy_score(y_true=y_train, y_pred=clf.predict(X_train))*100)\n",
    "print('Precision Score on train data:', precision_score(y_true=y_train, y_pred=clf.predict(X_train))*100)\n",
    "print('Recall Sensitivity of train data:', sensitivity*100)\n",
    "print('Specificity of train data:', specificity*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Accuracy Score, Precision Score, Recall Sensitivity and Specificity on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[36  3]\n",
      " [ 8 67]]\n",
      "Accuracy Score on test data: 90.35087719298247\n",
      "Precision Score on test data: 95.71428571428572\n",
      "Recall Sensitivity of train data: 92.3076923076923\n",
      "Specificity of train data: 89.33333333333333\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion Matrix: \\n', confusion)\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "print('Accuracy Score on test data:', accuracy_score(y_true=y_test, y_pred=y_pred)*100)\n",
    "print('Precision Score on test data:', precision_score(y_true=y_test, y_pred=y_pred)*100)\n",
    "print('Recall Sensitivity of train data:', sensitivity*100)\n",
    "print('Specificity of train data:', specificity*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the Decision Tree to increase the accuracy using 'min_samples_split' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Accuracy Score, Precision Score, Recall Sensitivity and Specificity on the train data using 'min_samples_split' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[173   0]\n",
      " [  0 282]]\n",
      "Accuracy Score on train data: 100.0\n",
      "Precision Score on train data: 100.0\n",
      "Recall Sensitivity of train data: 100.0\n",
      "Specificity of train data: 100.0\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_true=y_train, y_pred=clf.predict(X_train))\n",
    "print('Confusion Matrix: \\n', confusion)\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "print('Accuracy Score on train data:', accuracy_score(y_true=y_train, y_pred=clf.predict(X_train))*100)\n",
    "print('Precision Score on train data:', precision_score(y_true=y_train, y_pred=clf.predict(X_train))*100)\n",
    "print('Recall Sensitivity of train data:', sensitivity*100)\n",
    "print('Specificity of train data:', specificity*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Accuracy Score, Precision Score, Recall Sensitivity and Specificity on the test data using 'min_samples_split' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[36  3]\n",
      " [ 6 69]]\n",
      "Accuracy Score on the test data: 92.10526315789474\n",
      "Precision Score on the test data: 95.83333333333334\n",
      "Recall Sensitivity of the test data: 92.3076923076923\n",
      "Recall Specificity of train data: 92.0\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_true=y_test, y_pred=clf.predict(X_test))\n",
    "print('Confusion Matrix: \\n', confusion)\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "print('Accuracy Score on the test data:', accuracy_score(y_true=y_test, y_pred=clf.predict(X_test))*100)\n",
    "print('Precision Score on the test data:', precision_score(y_true=y_test, y_pred=clf.predict(X_test))*100)\n",
    "print('Recall Sensitivity of the test data:', sensitivity*100)\n",
    "print('Recall Specificity of train data:', specificity*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
